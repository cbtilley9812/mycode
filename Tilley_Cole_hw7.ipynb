{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\t(Ungraded) DataCamp Github Chapters: *Basic Work Flow* and *Repositories*; Read Guttag Ch 9-10\n",
    "(Note: You will need to complete your github.io webpage for the final exam -- I recommend you do this now and not leave it to the exam.)\n",
    "\n",
    "•\t(Graded) Below exercise. **Part I**: Scrape weather.com for zipcode 93405 scraping the following information in red, and storing it in a csv: feel's like, high, low, wind, humidity, dewpoint, pressure, and visibility. Just store the numbers (not %, mph, NE etc.). There are many ways to scrape the information, but the BeautifulSoup methods: .find(), .findall(), .text(), as well as using the list-like structure of each element scraped can accomplish it all.\n",
    "\n",
    "**Part II** Turn the scraper into a class called <span style=\"color:green\"> Weather()</span> with <span style=\"color:green\"> zip</span> as an attribute and a method that scrapes and stores the data in a csv called <span style=\"color:green\"> to_csv()</span>. Create two instances of the class for SLO and Harlem, zips 93405 and 10026. Call the method SLO.to_csv() and Harlem.to_csv(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries\n",
    "import csv\n",
    "import urllib.request as url\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(z):\n",
    "    # save the file \n",
    "    zip = z\n",
    "    # name the url\n",
    "    u = \"https://weather.com/weather/today/l/\" + zip + \":4:US\"\n",
    "\n",
    "\n",
    "    # first save the url to an html file\n",
    "    url.urlretrieve(u, \"slo.html\")\n",
    "\n",
    "    # now open the html file\n",
    "    html = open('slo.html','r').read()\n",
    "\n",
    "    # parse the html file with Beautiful Soup \n",
    "    return BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(zip):\n",
    "    soup = scraper(zip)\n",
    "    # scrape the temperature next to \"feels like\". Hint: look for span tag and class deg-feels\n",
    "    feels_like = soup.find('span', class_ = 'deg-feels').text\n",
    "\n",
    "\n",
    "    # scrape the high and low from today. Hint search for span tag and class deg-hilo-nowcard\n",
    "\n",
    "    high = soup.find_all('span', class_ = 'deg-hilo-nowcard')[0].text\n",
    "\n",
    "    low = soup.find_all('span', class_ = 'deg-hilo-nowcard')[1].text\n",
    "\n",
    "\n",
    "    # scrape wind, humidity, dewpoint, pressure and visibility. Hint: search for the td tag and class \"\"\n",
    "    contents = soup.find_all('td')\n",
    "    wind = contents[0].text\n",
    "    humidity = contents[1].text[0:2]\n",
    "    dewpoint = contents[2].text[0:2]\n",
    "    pressure = contents[3].text\n",
    "    visibility = contents[4].text\n",
    "\n",
    "    return [zip, feels_like, high, low, wind, humidity, dewpoint, pressure, visibility]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_er(d):\n",
    "    # open a csv file called 93405.csv\n",
    "    slo = open(d[0] +\".csv\",'w')\n",
    "\n",
    "    # create a writable excel object\n",
    "    # your code here\n",
    "    writer = csv.writer(slo, dialect='excel')\n",
    "    # write the first row of each column as show in the above screenshot\n",
    "    # your code here\n",
    "    writer.writerow(('zip', 'feel', 'high', 'low', 'wind, mph', 'humidity, %', 'dewpoint, degrees', 'pressure, inches', 'visibility, miles'))\n",
    "\n",
    "    # store the data\n",
    "    data = d\n",
    "\n",
    "    # write the data to the csv\n",
    "    # your code here\n",
    "    writer.writerow(data)\n",
    "    # close the csv file\n",
    "    slo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Now use the above code to write a class called Weather. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weather():\n",
    "    def __init__(self, zip):\n",
    "        self.zip = str(zip)\n",
    "\n",
    "    def to_csv(self):\n",
    "        csv_er(scrape(self.zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate two instances of the class Weather SLO(93405) and Harlem(10026). Call the method to_csv(). \n",
    "SLO = Weather(93405)\n",
    "SLO.to_csv()\n",
    "\n",
    "Harlem = Weather(10026)\n",
    "Harlem.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
